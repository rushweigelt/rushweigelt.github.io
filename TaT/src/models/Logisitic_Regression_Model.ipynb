{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logisitic_Regression_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnA1MtYUk0hbP1FQpO0ux+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushweigelt/rushweigelt.github.io/blob/master/TaT/src/models/Logisitic_Regression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNV-UuE9w8Y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate, train_test_split, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "from sklearn import metrics\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from keras.regularizers import L1L2\n",
        "import json\n",
        "from sklearn_porter import Porter\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGQSqKKL2d8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/rushweigelt/rushweigelt.github.io/master/TaT/data/combined_multi_bot_and_genuine_150.0k_split.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH5gF7ze6WWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "affcc952-d80c-4091-e5ae-67083c51b6a0"
      },
      "source": [
        "pip install sklearn-porter"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-porter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/b3/0d9f2b0800bc63b96dc9f707e3ec7565f49e4fba4fc0baf78cc61da0666f/sklearn_porter-0.7.4-py3-none-any.whl (144kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-porter) (1.12.0)\n",
            "Requirement already satisfied: scikit-learn>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from sklearn-porter) (0.22.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.14.1->sklearn-porter) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.14.1->sklearn-porter) (1.17.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.14.1->sklearn-porter) (0.14.1)\n",
            "Installing collected packages: sklearn-porter\n",
            "Successfully installed sklearn-porter-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbumsxSgy_Y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for test_train_split\n",
        "def LRTestTrainSplit(data_path):\n",
        "    data = pd.read_csv(data_path)\n",
        "    data.fillna(0, inplace=True)\n",
        "    x = data[['followerscount', 'friendscount', 'replycount', 'likecount', 'retweetcount', 'hashtagcount', 'urlcount', 'mentioncount']]\n",
        "    y = data['label']\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.35,  random_state=0)\n",
        "    #client = Client(processes=False)\n",
        "    lr = LogisticRegression()\n",
        "    #with joblib.parallel_backend('dask'):\n",
        "    lr.fit(x_train, y_train)\n",
        "\n",
        "    x_test.fillna(x_test.mean())\n",
        "    y_predict = lr.predict(x_test)\n",
        "    '''\n",
        "    #save attempt\n",
        "    model_param = {}\n",
        "    model_param['coef'] = list(lr.coef_)\n",
        "    model_param['intercept'] = lr.intercept_.tolist()\n",
        "    json_txt = json.dumps(model_param, indent=4)\n",
        "    '''\n",
        "    '''THIS MODEL ISNT SUPPORTED BY PORTER\n",
        "    #save attempt 2\n",
        "    porter = Porter(lr, language='java')\n",
        "    output = porter.export(embed_data=True)\n",
        "    print(output)\n",
        "    '''\n",
        "    with open('lr.param.txt', w) as file:\n",
        "      file.write(json_text)\n",
        "    confusion_matrix = pd.crosstab(y_test, y_predict, rownames=['Actual'], colnames=['Predicted'])\n",
        "    print(confusion_matrix)\n",
        "    matrix = sb.heatmap(confusion_matrix, annot=True)\n",
        "\n",
        "    print('Accuracy: ', metrics.accuracy_score(y_test, y_predict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpFhX7wPzCOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LR_KFold(data_path):\n",
        "    data = pd.read_csv(data_path)\n",
        "    data.fillna(0, inplace=True)\n",
        "    x = data[['followerscount', 'friendscount', 'replycount', 'likecount', 'retweetcount', 'hashtagcount', 'urlcount', 'mentioncount']]\n",
        "    y = data['label']\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    #x = scaler.fit_transform(x)\n",
        "    #y = scaler.fit_transform(y)\n",
        "    #kf = KFold(n_splits=10, shuffle=True)\n",
        "    #kf.get_n_splits(x)\n",
        "    #kf.get_n_splits(y)\n",
        "    lr = LogisticRegression()\n",
        "    cv_results = cross_validate(lr, x, y, cv=10)\n",
        "    print(cv_results['test_score'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcZU4KPk9VQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Keras_LR(data_path):\n",
        "  #Get Data\n",
        "  data = pd.read_csv(data_path)\n",
        "  data.fillna(0, inplace=True)\n",
        "  x = data[['followerscount', 'friendscount', 'replycount', 'likecount', 'retweetcount', 'hashtagcount', 'urlcount', 'mentioncount']]\n",
        "  y = data['label']\n",
        "  #map bot = 0, genuine = 1\n",
        "  y = [0 if x=='bot' else x for x in y]\n",
        "  y = [1 if x=='genuine' else x for x in y]\n",
        "  print(y[-100:-1])\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.35,  random_state=0)\n",
        "  #Build Model\n",
        "  keras_LR_model = Build_Keras_Model()\n",
        "  print(keras_LR_model.summary())\n",
        "  #Fit Model\n",
        "  keras_LR_model.fit(x_train, y_train, epochs=3, batch_size=5, verbose=1)\n",
        "  #Save Model\n",
        "  Save_Keras_Model(keras_LR_model)\n",
        "  #Evaluate\n",
        "  Evaluate_Keras_Model(keras_LR_model, x_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fszzgOw9vIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Build_Keras_Model():\n",
        "  model = Sequential()\n",
        "  #Two becayse we have a binary categorizer\n",
        "  model.add(Dense(2, activation='softmax', kernel_regularizer=L1L2(l1=0.0, l2=0.1), input_dim=8))\n",
        "  model.add(Dense(1, activation='softmax'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obf8jmZG-K-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Save_Keras_Model(model):\n",
        "    # saving model\n",
        "    json_model = model.to_json()\n",
        "    open('model_architecture.json', 'w').write(json_model)\n",
        "    # saving weights\n",
        "    model.save_weights('model_weights.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUsSWihZ-NLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Evaluate_Keras_Model(model, x_test_data):\n",
        "  predictions = model.predict_classes(x_test_data, verbose=1)\n",
        "  print(predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BpY7HyUzHNK",
        "colab_type": "code",
        "outputId": "f1b02d01-7c0e-4619-a660-870d374aeef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "LRTestTrainSplit(url)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2828: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neural_network.multilayer_perceptron module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neural_network. Anything that cannot be imported from sklearn.neural_network is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9e72c908a946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLRTestTrainSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-260d0c2ed8a9>\u001b[0m in \u001b[0;36mLRTestTrainSplit\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     '''\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#save attempt 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'java'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn_porter/Porter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, language, method, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Currently the given estimator '{estimator}' isn't\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0;34m\" supported.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Import estimator class:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Currently the given estimator 'LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)' isn't supported."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X86jvEzg9qqm",
        "colab_type": "code",
        "outputId": "0c35f807-e41a-4c3d-ce5d-4995eb4e7560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "Keras_LR(url)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2828: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_26 (Dense)             (None, 2)                 18        \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 21\n",
            "Trainable params: 21\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "195000/195000 [==============================] - 53s 271us/step - loss: 7.9672 - acc: 0.5004\n",
            "Epoch 2/3\n",
            "195000/195000 [==============================] - 52s 265us/step - loss: 7.9644 - acc: 0.5004\n",
            "Epoch 3/3\n",
            "195000/195000 [==============================] - 51s 263us/step - loss: 7.9644 - acc: 0.5004\n",
            "105000/105000 [==============================] - 2s 19us/step\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap9c0hxi8jDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SaveModel(model):\n",
        "  model.model.to_json"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}