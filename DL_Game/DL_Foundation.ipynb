{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Foundation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9YEmY8q7sIbaXCmL6DEZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushweigelt/rushweigelt.github.io/blob/master/DL_Foundation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NunHzHj3nN0N",
        "colab_type": "text"
      },
      "source": [
        "Rush Weigelt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZThyXm3nSGx",
        "colab_type": "text"
      },
      "source": [
        "1/10/20\n",
        "First Attempt at DL Pictionary\n",
        "Based on Zaid Alyafeai's Medium Article\n",
        "(Thank You for the incredible walkthrough!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3RM9WqesdKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ad484421-d94f-4b9b-d7fd-3d08fe7ab38b"
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-10 23:40:35--  https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘mini_classes.txt.2’\n",
            "\n",
            "\rmini_classes.txt.2    0%[                    ]       0  --.-KB/s               \rmini_classes.txt.2  100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2020-01-10 23:40:36 (230 MB/s) - ‘mini_classes.txt.2’ saved [760/760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdPrzQrnsnbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"mini_classes.txt\", \"r\")\n",
        "classes = f.readlines()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a31g00aBsw3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOUDRkkgtHZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcdd9920-6ae0-42a7-f6d8-d4166c6b793b"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLKzPDEHoAQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "vfold_ratio = 0.2\n",
        "max_images_per_class = 5000\n",
        "validation_split = 0.1\n",
        "batch_size = 256\n",
        "verbose = 2\n",
        "epochs=5\n",
        "\n",
        "#Start by Downloading Data from Google\n",
        "def download_data():\n",
        "\n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', \"%20\")\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrQ3cdBCtoR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05d42a56-a93d-4f7a-e82b-a09bb5fbc9a1"
      },
      "source": [
        "download_data()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02mw8XTMtpiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the subset of data we want\n",
        "#Will return: X Train Set, X Test Set, Y Train Set, Y Test Set, and Class Names\n",
        "def load_data(root, vfold_ratio=vfold_ratio, max_items_per_class=max_images_per_class):\n",
        "  all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "  #init vars\n",
        "  x = np.empty([0, 784])\n",
        "  y = np.empty([0])\n",
        "  class_names = []\n",
        "\n",
        "  #load a subset of the data into memory\n",
        "  for idx, file in enumerate(all_files):\n",
        "    data = np.load(file)\n",
        "    data = data[0: max_items_per_class, :]\n",
        "    labels = np.full(data.shape[0], idx)\n",
        "\n",
        "    x = np.concatenate((x, data), axis=0)\n",
        "    y = np.append(y, labels)\n",
        "\n",
        "    class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "    class_names.append(class_name)\n",
        "\n",
        "  data = None\n",
        "  labels = None\n",
        "\n",
        "  #Seperate into training and testing datasets\n",
        "  permutation = np.random.permutation(y.shape[0])\n",
        "  x = x[permutation, :]\n",
        "  y = y[permutation]\n",
        "\n",
        "  vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "  x_test = x[0:vfold_size, :]\n",
        "  y_test = y[0:vfold_size]\n",
        "\n",
        "  x_train = x[vfold_size:x.shape[0], :]\n",
        "  y_train = y[vfold_size:y.shape[0]]\n",
        "\n",
        "  return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cevMH2ir2oL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "970e74ae-fcea-445b-b614-464500ec4896"
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28\n",
        "print(len(x_train))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QmkDtZjt6kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show a random drawing we downloaded earlier\n",
        "def mini_test_show_rand_data():\n",
        "  %matplotlib inline\n",
        "  idx = random.randint(0, len(x_train))\n",
        "  plt.imshow(x_train[idx].reshape(28,28))\n",
        "  print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2BbDkiwugo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "be1ba0d1-358e-403c-ec4b-98228dc938ed"
      },
      "source": [
        "mini_test_show_rand_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "triangle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22cjZgtnvYGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(x_train, x_test, y_train, y_test):\n",
        "  #Reshape and Normalize\n",
        "  x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "  x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "  x_train /= 255.0\n",
        "  x_test /= 255.0\n",
        "\n",
        "  #convert class vectors to matrices\n",
        "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzUJzpqSwWo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = preprocess_data(x_train, x_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQrZIoTDwZDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(x_train):\n",
        "  model = keras.Sequential()\n",
        "  #Convolution > Pool > Convolution > Pool > Convolution > Pool > Flatten > Dense > Dense\n",
        "  #Convo > Pool batch\n",
        "  model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Convolution2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Convolution2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  #Rest\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(100, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcH8WB-Bxr36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c48fc504-f7cf-476e-857f-836f505f14bb"
      },
      "source": [
        "model = define_model(x_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU6s6RASxw9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(loss, metrics):\n",
        "  adam = tf.train.AdamOptimizer()\n",
        "  model.compile(loss=loss, optimizer=adam, metrics=[metrics])\n",
        "  print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwbovpP8x9aa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "94e72cbe-23d9-408e-9580-4fe69c4742b7"
      },
      "source": [
        "trained_model = train_model('categorical_crossentropy', 'top_k_categorical_accuracy')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               36992     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 63,940\n",
            "Trainable params: 63,940\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un8SVXdizqxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "18f4948e-ecdf-4445-a791-4aa2effecd5f"
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=validation_split, batch_size = batch_size, verbose=verbose, epochs=epochs)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 360000 samples, validate on 40000 samples\n",
            "Epoch 1/5\n",
            "360000/360000 - 18s - loss: 1.8959 - top_k_categorical_accuracy: 0.7885 - val_loss: 1.3742 - val_top_k_categorical_accuracy: 0.8767\n",
            "Epoch 2/5\n",
            "360000/360000 - 9s - loss: 1.2676 - top_k_categorical_accuracy: 0.8905 - val_loss: 1.2076 - val_top_k_categorical_accuracy: 0.8967\n",
            "Epoch 3/5\n",
            "360000/360000 - 9s - loss: 1.1259 - top_k_categorical_accuracy: 0.9061 - val_loss: 1.0942 - val_top_k_categorical_accuracy: 0.9094\n",
            "Epoch 4/5\n",
            "360000/360000 - 9s - loss: 1.0442 - top_k_categorical_accuracy: 0.9146 - val_loss: 1.0346 - val_top_k_categorical_accuracy: 0.9151\n",
            "Epoch 5/5\n",
            "360000/360000 - 10s - loss: 0.9871 - top_k_categorical_accuracy: 0.9204 - val_loss: 1.0101 - val_top_k_categorical_accuracy: 0.9176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb3e38bdc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wscSB540N4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afe57c07-83b6-4a3c-fa8d-b9e72e3d39d6"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy: {:0.2f}%'.format(score[1]*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 91.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWKOGS1w3qUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7ac97ed7-3d9b-43f0-c5f6-dfd39c1e141e"
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U586vB6p3tSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be75fa53-ee08-4981-8c87-4d4958ad2da7"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/73/f7ee6edced75b7dfe43916203f1b2e85dd14cba087a090e6372cbd82e462/tensorflowjs-1.4.0-py3-none-any.whl (56kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 30kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25hCollecting PyInquirer==1.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/4c/434b7c454010a284b49d6f1d446fe8dc5960415613d8c0225b9e2efb6724/PyInquirer-1.0.3.tar.gz\n",
            "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Collecting tensorflow-hub==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/be/f18c352d84382d9c795a0f37eaf16d42ace7d161fbb0ad20bdcd5e550015/tensorflow_hub-0.5.0-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.3MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 202kB/s \n",
            "\u001b[?25hCollecting six==1.11.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.2.2)\n",
            "Collecting prompt_toolkit==1.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/3d/b25d35a9f0d381dd1c02d8e04b37c353caaaff4bc32150328eeebe4931f5/prompt_toolkit-1.0.14-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 50.5MB/s \n",
            "\u001b[?25hCollecting Pygments>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/39/32da3184734730c0e4d3fa3b2b5872104668ad6dc1b5a73d8e477e5fe967/Pygments-2.5.2-py2.py3-none-any.whl (896kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 64.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2016.11.21 in /usr/local/lib/python3.6/dist-packages (from PyInquirer==1.0.3->tensorflowjs) (2019.12.20)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (1.15.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (0.33.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (0.9.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->tensorflowjs) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt_toolkit==1.0.14->PyInquirer==1.0.3->tensorflowjs) (0.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0->tensorflowjs) (42.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->tensorflowjs) (0.16.0)\n",
            "Building wheels for collected packages: PyInquirer\n",
            "  Building wheel for PyInquirer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyInquirer: filename=PyInquirer-1.0.3-cp36-none-any.whl size=32853 sha256=15fcac2252b43f7faa6d35f5395def430d81f1fdac1875fb796807c8f99bd6c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/6c/b1/3e4b0e8daf42a92883c7641c0ea8ffb62e0490ebed2faa55ad\n",
            "Successfully built PyInquirer\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, prompt-toolkit, Pygments, PyInquirer, numpy, tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: Pygments 2.1.3\n",
            "    Uninstalling Pygments-2.1.3:\n",
            "      Successfully uninstalled Pygments-2.1.3\n",
            "  Found existing installation: numpy 1.17.5\n",
            "    Uninstalling numpy-1.17.5:\n",
            "      Successfully uninstalled numpy-1.17.5\n",
            "  Found existing installation: tensorflow-hub 0.7.0\n",
            "    Uninstalling tensorflow-hub-0.7.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.7.0\n",
            "Successfully installed PyInquirer-1.0.3 Pygments-2.5.2 numpy-1.16.4 prompt-toolkit-1.0.14 six-1.11.0 tensorflow-hub-0.5.0 tensorflowjs-1.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "prompt_toolkit",
                  "pygments",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ4QLxHK3u_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPd8S48533qd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f7381d50-1b01-45ba-f4d5-2d080e0577aa"
      },
      "source": [
        "!zip -r model.zip model"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/group1-shard1of1.bin (deflated 7%)\n",
            "  adding: model/model.json (deflated 85%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0K594PC4ELr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('model.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}